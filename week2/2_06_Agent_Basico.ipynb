{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evinracher/3010090-ontological-engineering/blob/main/week2/2_06_Agent_Basico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f67efe04-0d27-4710-a3c0-a405cd80c46d",
      "metadata": {
        "id": "f67efe04-0d27-4710-a3c0-a405cd80c46d"
      },
      "source": [
        "## AGENTE BASICO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Obtener la API key desde userdata\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Opcional: Guardarla como variable de entorno\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "\n",
        "# Verificar que se haya cargado correctamente\n",
        "print(\"API Key cargada:\", \"SÃ­\" if api_key else \"No\")\n",
        "print(\"Primeros caracteres:\", api_key[:10] if api_key else \"No encontrada\")"
      ],
      "metadata": {
        "id": "ZPjKuDLtf277"
      },
      "id": "ZPjKuDLtf277",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"langchain>=1,<2\" langchain-core langchain-community langchain-text-splitters"
      ],
      "metadata": {
        "id": "XCMD5ZDH6cpn"
      },
      "id": "XCMD5ZDH6cpn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "yjOT53Ye6drn"
      },
      "id": "yjOT53Ye6drn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "print(\"âœ… LangChain-Gemini instalado correctamente\")"
      ],
      "metadata": {
        "id": "mni2246j8OBv"
      },
      "id": "mni2246j8OBv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46d18f5-bc4c-4355-93ab-89387ff06dc2",
      "metadata": {
        "id": "f46d18f5-bc4c-4355-93ab-89387ff06dc2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir el contexto de ejecuciÃ³n a proporcionar al agente y a las herramientas (tools) acceso a la base de datos."
      ],
      "metadata": {
        "id": "-_s0tSwk-oPT"
      },
      "id": "-_s0tSwk-oPT"
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "\n",
        "# define context structure to support dependency injection\n",
        "@dataclass\n",
        "class RuntimeContext:\n",
        "    db: SQLDatabase"
      ],
      "metadata": {
        "id": "51KnItww-cEa"
      },
      "id": "51KnItww-cEa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta herramienta (tool) se conectarÃ¡ a la base de datos. Observe el uso de `get_runtime` para acceder al contexto de ejecuciÃ³n del grafo."
      ],
      "metadata": {
        "id": "oAAkhWb__OJU"
      },
      "id": "oAAkhWb__OJU"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from langgraph.runtime import get_runtime\n",
        "\n",
        "@tool\n",
        "def execute_sql(query: str) -> str:\n",
        "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
        "    runtime = get_runtime(RuntimeContext)\n",
        "    db = runtime.context.db\n",
        "\n",
        "    try:\n",
        "        return db.run(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\""
      ],
      "metadata": {
        "id": "ViW-ZlRl_XcO"
      },
      "id": "ViW-ZlRl_XcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrega un *system prompt* para definir el comportamiento de tus agentes."
      ],
      "metadata": {
        "id": "k1dCQMwhDK17"
      },
      "id": "k1dCQMwhDK17"
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a careful SQLite analyst.\n",
        "\n",
        "Rules:\n",
        "- Think step-by-step.\n",
        "- When you need data, call the tool `execute_sql` with ONE SELECT query.\n",
        "- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.\n",
        "- Limit to 5 rows of output unless the user explicitly asks otherwise.\n",
        "- If the tool returns 'Error:', revise the SQL and try again.\n",
        "- Prefer explicit column lists; avoid SELECT *.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vHe6FispDXCW"
      },
      "id": "vHe6FispDXCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Â¡Crear el agente! AÃ±ade un: model, tools, a prompt, y el acceso runtime, and vamos! Puede elegir muchos agentes de la lista de [integracion](https://docs.langchain.com/oss/python/integrations/providers/overview)."
      ],
      "metadata": {
        "id": "HC9L07QFEVek"
      },
      "id": "HC9L07QFEVek"
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "XgxOzB9YXNE3"
      },
      "id": "XgxOzB9YXNE3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# ðŸ¤– Crear modelo Gemini\n",
        "# ========================================\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",  # âœ… Modelo vÃ¡lido\n",
        "    temperature=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "Y5NpUyQSMlBN"
      },
      "id": "Y5NpUyQSMlBN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,  # âœ… Objeto Gemini (NO cadena)\n",
        "    tools=[execute_sql],\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    context_schema=RuntimeContext,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "b6dWRQQIGv9d"
      },
      "id": "b6dWRQQIGv9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRIMERA CONSULTA**"
      ],
      "metadata": {
        "id": "9lCx_hCzSm73"
      },
      "id": "9lCx_hCzSm73"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "question = \"Which are the annual sales per year in  USA??\"\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [HumanMessage(content=question)]\n",
        "}\n",
        "\n",
        "for step in agent.stream(\n",
        "    inputs,\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    msg = step.get(\"messages\", [])[-1]\n",
        "    msg.pretty_print()"
      ],
      "metadata": {
        "id": "emIlrEJpieWE"
      },
      "id": "emIlrEJpieWE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEGUNDA CONSULTA**"
      ],
      "metadata": {
        "id": "-gB4YC-GSval"
      },
      "id": "-gB4YC-GSval"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How many attributes does the album table have??\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": question},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "or-BLGJpki7C"
      },
      "id": "or-BLGJpki7C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TERCERA CONSULTA**"
      ],
      "metadata": {
        "id": "zctS8M60S2q7"
      },
      "id": "zctS8M60S2q7"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "question = \"Which table has the largest number of entries?\"\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [HumanMessage(content=question)]\n",
        "}\n",
        "\n",
        "for step in agent.stream(\n",
        "    inputs,\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    msg = step.get(\"messages\", [])[-1]\n",
        "    msg.pretty_print()"
      ],
      "metadata": {
        "id": "5TlnXHu9aeUq"
      },
      "id": "5TlnXHu9aeUq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUARTA CONSULTA**"
      ],
      "metadata": {
        "id": "w8fIp9D6S8QE"
      },
      "id": "w8fIp9D6S8QE"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "question = \"Obtener los 10 principales artistas por cantidad de ventas. \"\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [HumanMessage(content=question)]\n",
        "}\n",
        "\n",
        "for step in agent.stream(\n",
        "    inputs,\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    msg = step.get(\"messages\", [])[-1]\n",
        "    msg.pretty_print()"
      ],
      "metadata": {
        "id": "P1dWnnfPoOLq"
      },
      "id": "P1dWnnfPoOLq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUINTA CONSULTA**"
      ],
      "metadata": {
        "id": "0UU9S95_TBXl"
      },
      "id": "0UU9S95_TBXl"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which genre on average has the longest track?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": question},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "qm06JxtfRYxO"
      },
      "id": "qm06JxtfRYxO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEXTA CONSULTA**"
      ],
      "metadata": {
        "id": "I1F0jZdvbqAP"
      },
      "id": "I1F0jZdvbqAP"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the first 5 artist in the 'Artist' table? execute it\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": question},\n",
        "    context={\"db\": db},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "luIggl74agm1"
      },
      "id": "luIggl74agm1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_env",
      "language": "python",
      "name": "langchain_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}