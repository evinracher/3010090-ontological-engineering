{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evinracher/3010090-ontological-engineering/blob/main/week3/part2/05_BD_vectores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62baa5ee",
      "metadata": {
        "id": "62baa5ee"
      },
      "source": [
        "# 01 - Cargadores de documentos con LangChain 1.0 y Gemini üá®üá¥\n",
        "\n",
        "En este cuaderno trabajaremos el tema de **conectores de datos** en el contexto de **LangChain 1.0** usando como LLM **Gemini**.\n",
        "\n",
        "Ver√°s los siguientes temas b√°sicos, listos para ejecutar en **Google Colab**:\n",
        "\n",
        "1. Instalaci√≥n de dependencias para LangChain 1.0 + Gemini  \n",
        "2. Configuraci√≥n de la API Key de Gemini  \n",
        "3. Cargadores de documentos (PDF como caso base)  \n",
        "4. Transformaci√≥n de documentos: divisi√≥n en *chunks*  \n",
        "5. Creaci√≥n de *embeddings* con Gemini  \n",
        "6. Creaci√≥n de una base vectorial (FAISS)  \n",
        "7. Cadena de pregunta-respuesta (RAG) sobre el PDF usando Gemini  \n",
        "\n",
        "> **Nota:** Todos los ejemplos est√°n simplificados para que sirvan como plantilla did√°ctica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15258831",
      "metadata": {
        "id": "15258831"
      },
      "source": [
        "## 1. Instalaci√≥n de librer√≠as necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b95ddb8",
      "metadata": {
        "id": "3b95ddb8",
        "outputId": "6eefe3ae-60af-42e6-db77-e23039b315ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/501.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m491.5/501.4 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m501.4/501.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.0/331.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Si est√°s en Google Colab, ejecuta esta celda primero.\n",
        "# Puede tardar un poco.\n",
        "\n",
        "!pip -q install -U langchain-core langchain-community langchain-text-splitters google-generativeai langchain-google-genai fastembed faiss-cpu pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63dc2732",
      "metadata": {
        "id": "63dc2732"
      },
      "source": [
        "## 2. Configuraci√≥n de la clave de API de Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd2b0a9b",
      "metadata": {
        "id": "dd2b0a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff664950-02f6-4fa9-aefb-756edbc268c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key cargada: S√≠\n",
            "Primeros caracteres: AIzaSyDx4e\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Obtener la API key desde userdata\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Opcional: Guardarla como variable de entorno\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "\n",
        "# Verificar que se haya cargado correctamente\n",
        "print(\"API Key cargada:\", \"S√≠\" if api_key else \"No\")\n",
        "print(\"Primeros caracteres:\", api_key[:10] if api_key else \"No encontrada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e0a866e",
      "metadata": {
        "id": "0e0a866e"
      },
      "source": [
        "## 3. Importaciones base: LangChain 1.0 + Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa6fbde7",
      "metadata": {
        "id": "aa6fbde7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e1257a-e274-4135-c41c-afcb2f5d9126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente.\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be4efb6",
      "metadata": {
        "id": "4be4efb6"
      },
      "source": [
        "## 4. Cargadores de documentos: ejemplo con PDF\n",
        "\n",
        "En este ejemplo vamos a:\n",
        "\n",
        "1. Subir un archivo PDF a Colab  \n",
        "2. Cargarlo con `PyPDFLoader`  \n",
        "3. Ver parte de su contenido\n",
        "\n",
        "> Puedes usar cualquier PDF que tengas a mano (art√≠culo, paper, cap√≠tulo de libro, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "836d8d2a",
      "metadata": {
        "id": "836d8d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d76c337d-5ae3-44fd-a84b-1c68573680ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89f4f664-d53b-4ea7-b89a-eaf9e6b5f7e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89f4f664-d53b-4ea7-b89a-eaf9e6b5f7e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Documento tecnologiÃÅas emergentes.pdf to Documento tecnologiÃÅas emergentes.pdf\n",
            "üìÑ Archivo cargado: Documento tecnologiÃÅas emergentes.pdf\n"
          ]
        }
      ],
      "source": [
        "# 4.1. Subir el archivo PDF desde tu equipo\n",
        "# Ejecuta esta celda y selecciona un archivo .pdf\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "upload = files.upload()\n",
        "pdf_path = list(upload.keys())[0]\n",
        "print(f\"üìÑ Archivo cargado: {pdf_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26739f62",
      "metadata": {
        "id": "26739f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae3c500-20fa-4a9c-9526-d28e831c7661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ P√°ginas cargadas: 4\n",
            "\n",
            "üìÑ Vista previa del contenido de la primera p√°gina:\n",
            "\n",
            "Estas son las 9 tecnolog√≠as \n",
            "emergentes para el pr√≥ximo \n",
            "2025 \n",
            "  \n",
            "‚ÄúQue la tecnolog√≠a ha cambiado nuestra manera de vivir e interactuar \n",
            "es un hecho. Sin embargo, a√∫n no somos conscientes de las \n",
            "potencialidades de usos de las tecnolog√≠as.Por ejemplo, para el a√±o \n",
            "2025 se espera una verdadera revoluci√≥n tecnol√≥gica, sobre todo \n",
            "enfocado en el sector bio-m√©dico pero tambi√©n en las relaciones \n",
            "humanas entre individuos a distancia, en la protecci√≥n del medio \n",
            "ambiente o en la protecci√≥n de nuestros datos personales‚Äù, afirma \n",
            "Juan Quintanilla, director general de Syntonize. \n",
            "9 Tecnolog√≠as emergentes seg√∫n Syntonize \n",
            "La aplicaci√≥n de nuevas tecnolog√≠as que hagan m√°s f√°cil la vida a \n",
            "profesionales, estudiantes, mayores, empresas o instituciones \n",
            "p√∫blicas se espera que aumente en los pr√≥ximos a√±os. Entre ellas se \n",
            "encuentran; \n",
            "ÔÇ∑ Producci√≥n optimizada por la Inteligencia Artificial: las \n",
            "empresas est√°n adoptando r√°pidamente tecnolog√≠as basadas \n",
            "en la nube. Gracias a ello, podr√°n agregar, transf\n"
          ]
        }
      ],
      "source": [
        "# 4.2. Cargar el PDF usando PyPDFLoader\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"‚úÖ P√°ginas cargadas: {len(docs)}\")\n",
        "print(\"\\nüìÑ Vista previa del contenido de la primera p√°gina:\\n\")\n",
        "print(docs[0].page_content[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76db347d",
      "metadata": {
        "id": "76db347d"
      },
      "source": [
        "## 5. Transformaci√≥n de documentos: divisi√≥n en *chunks*\n",
        "\n",
        "Para usar un LLM de forma eficiente y tambi√©n para crear una base vectorial,\n",
        "es conveniente dividir el documento en fragmentos (*chunks*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "feeb9577",
      "metadata": {
        "id": "feeb9577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20def1f3-09e3-4ec6-c50f-46aab574fdb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ N√∫mero de chunks generados: 9\n",
            "\n",
            "üìÑ Ejemplo de un chunk:\n",
            "\n",
            "Estas son las 9 tecnolog√≠as \n",
            "emergentes para el pr√≥ximo \n",
            "2025 \n",
            "  \n",
            "‚ÄúQue la tecnolog√≠a ha cambiado nuestra manera de vivir e interactuar \n",
            "es un hecho. Sin embargo, a√∫n no somos conscientes de las \n",
            "potencialidades de usos de las tecnolog√≠as.Por ejemplo, para el a√±o \n",
            "2025 se espera una verdadera revoluci√≥n tecnol√≥gica, sobre todo \n",
            "enfocado en el sector bio-m√©dico pero tambi√©n en las relaciones \n",
            "humanas entre individuos a distancia, en la protecci√≥n del medio \n",
            "ambiente o en la protecci√≥n de nuestros \n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,      # longitud m√°xima de cada chunk\n",
        "    chunk_overlap=100,   # solapamiento entre chunks para mantener contexto\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "print(f\"‚úÖ N√∫mero de chunks generados: {len(chunks)}\")\n",
        "print(\"\\nüìÑ Ejemplo de un chunk:\\n\")\n",
        "print(chunks[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76eaf46",
      "metadata": {
        "id": "d76eaf46"
      },
      "source": [
        "## 6. Incrustaciones de texto (Embeddings) con Gemini\n",
        "\n",
        "Usaremos el modelo `BAAI/bge-small-en-v1.5` de FastEmbedEmbeddings para convertir cada chunk\n",
        "en un vector num√©rico de alta dimensi√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "321df170",
      "metadata": {
        "id": "321df170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "9ce9201e69f74ec59a68f66fbe440e7a",
            "0f0184a8f3574fb4a0b039f8baa3823b",
            "9d7e2a3a69fb4e10afa06781397e536d",
            "b20b284ddea14bcca74fb66f2da95ba6",
            "3b153d2d130c487d8af0d79157feb502",
            "07408d95dac8495a9b3ec3304c1d0dfc",
            "7b338d4603b5447b97ab280bb20318d4",
            "5f124eb69e194623a67c4e4350e774ee",
            "ea808fbcedaf46029e138c5cbe2f4853",
            "08582fc29caf44a28c3a394689dc46a0",
            "ec738af94f7640559f43da7646fb1b03",
            "41e12b93d02848568f1ae35d34407be8",
            "d0acc3fdbe58444eba55051f5384cf97",
            "a8f1a1eab935476784b75a3f14913610",
            "073512fedafa4665b91d46de584edf15",
            "339e62957d5d485aa81e24c1ccf73292",
            "e7566967d99349f1bd9cf5320cb638b8",
            "3bcb9529adbc49b2a57815254d8387ad",
            "af36f334d1514bb9be01fa7e776cb776",
            "56c8de3ac5bb49be824f3a261ba26874",
            "1df700a1dfd0476ea77ba368ed42c761",
            "7a65aa957ed048e69958c0793b80f497"
          ]
        },
        "outputId": "ba7ada02-1551-404c-ee36-e97c2a5906bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ce9201e69f74ec59a68f66fbe440e7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41e12b93d02848568f1ae35d34407be8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi√≥n del vector de ejemplo: 384\n"
          ]
        }
      ],
      "source": [
        "embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "# Probar con un texto simple\n",
        "vector_ejemplo = embeddings.embed_query(\"La inteligencia artificial est√° transformando la educaci√≥n.\")\n",
        "print(f\"Dimensi√≥n del vector de ejemplo: {len(vector_ejemplo)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86496cac",
      "metadata": {
        "id": "86496cac"
      },
      "source": [
        "## 7. Creaci√≥n de una base vectorial con FAISS\n",
        "\n",
        "Ahora creamos una base de datos vectorial a partir de los *chunks* usando FAISS.\n",
        "Esto permitir√° hacer **b√∫squeda sem√°ntica** sobre el contenido del PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d4375b5",
      "metadata": {
        "id": "4d4375b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5675bec8-a765-49dd-92a5-babacdec6bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Base vectorial creada y retriever configurado.\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.from_documents(chunks, embeddings) # Se guarda el texto y la representaci√≥n sem√°ntica\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4}) # Primeros 4 resultados\n",
        "\n",
        "print(\"‚úÖ Base vectorial creada y retriever configurado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba373b4",
      "metadata": {
        "id": "0ba373b4"
      },
      "source": [
        "## 8. Definir el modelo de chat Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "84e6830b",
      "metadata": {
        "id": "84e6830b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d9f098-7fc8-4d38-f413-a799196389bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo Gemini configurado: models/gemini-2.5-flash-lite\n"
          ]
        }
      ],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.5-flash-lite\",\n",
        "    temperature=0.3,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Modelo Gemini configurado: models/gemini-2.5-flash-lite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c7f768",
      "metadata": {
        "id": "e5c7f768"
      },
      "source": [
        "## 9. Cadena de Pregunta-Respuesta (RAG) sobre el PDF\n",
        "\n",
        "Usaremos el patr√≥n LCEL de LangChain 1.0 para construir una cadena que:\n",
        "\n",
        "1. Recupera los chunks m√°s relevantes v√≠a `retriever`  \n",
        "2. Forma un prompt con contexto + pregunta del usuario  \n",
        "3. Env√≠a el prompt a Gemini  \n",
        "4. Devuelve una respuesta en lenguaje natural\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4d66e5ce",
      "metadata": {
        "id": "4d66e5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc8b894-ba58-4cfa-ad80-249b8c2feb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cadena RAG construida correctamente.\n"
          ]
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Eres un asistente experto en comprensi√≥n de documentos.\n",
        "\n",
        "Usando exclusivamente la siguiente informaci√≥n de contexto, responde de forma clara,\n",
        "estructurada y en espa√±ol a la pregunta del usuario.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta:\n",
        "{question}\n",
        "\"\"\")\n",
        "\n",
        "# 1) Definimos un paso que obtiene contexto desde el retriever\n",
        "def get_context(query: str):\n",
        "    docs_relacionados = retriever.invoke(query)   # << CORRECTO EN LC 1.0\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs_relacionados])\n",
        "\n",
        "\n",
        "# 2) Construimos la cadena con LCEL\n",
        "rag_chain = (\n",
        "    RunnableParallel(\n",
        "        context=lambda x: get_context(x[\"question\"]),\n",
        "        question=RunnablePassthrough()\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Cadena RAG construida correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4493caa7",
      "metadata": {
        "id": "4493caa7"
      },
      "source": [
        "## 10. Probar la cadena RAG con tus propias preguntas\n",
        "\n",
        "Ahora puedes hacer preguntas en lenguaje natural sobre el contenido del PDF cargado.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¬øCu√°l es el tema principal del documento y cu√°les son sus conclusiones m√°s importantes?\"\n",
        "\n",
        "respuesta = rag_chain.invoke({\"question\": pregunta})\n",
        "\n",
        "print(\"üß† Pregunta:\", pregunta)\n",
        "print(\"\\nüìå Respuesta de Gemini:\\n\")\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "8hEbat6Kk5ug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f184119b-1561-4713-e181-0ab2c38b710e"
      },
      "id": "8hEbat6Kk5ug",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Pregunta: ¬øCu√°l es el tema principal del documento y cu√°les son sus conclusiones m√°s importantes?\n",
            "\n",
            "üìå Respuesta de Gemini:\n",
            "\n",
            "El documento aborda las transformaciones tecnol√≥gicas esperadas en los pr√≥ximos a√±os y sus impactos en diversos √°mbitos.\n",
            "\n",
            "Las conclusiones m√°s importantes son:\n",
            "\n",
            "*   **Avances en la comprensi√≥n de pat√≥genos:** La tecnolog√≠a permitir√° acelerar el muestreo, digitalizaci√≥n e interpretaci√≥n de datos de microbiomas, lo que transformar√° la comprensi√≥n de la propagaci√≥n de pat√≥genos.\n",
            "*   **Privacidad como prioridad:** La privacidad ser√° generalizada y priorizada, considerando la protecci√≥n y control de activos de datos confidenciales como la norma. Las tecnolog√≠as de mejora de la privacidad se convertir√°n en una categor√≠a tecnol√≥gica propia y un elemento fundamental en las estrategias empresariales.\n",
            "*   **Aumento de la aplicaci√≥n de nuevas tecnolog√≠as:** Se espera un incremento en la aplicaci√≥n de tecnolog√≠as que faciliten la vida de profesionales, estudiantes, mayores, empresas e instituciones p√∫blicas.\n",
            "*   **Impacto del 5G:** El 5G mejorar√° la econom√≠a global y salvar√° vidas al resolver la falta de confiabilidad de redes de baja latencia, permitiendo servicios de alta capacidad como telesalud, telecirug√≠a y servicios de emergencia.\n",
            "*   **Nueva normalidad en el manejo del c√°ncer:** La tecnolog√≠a impulsar√° el conocimiento y el empoderamiento, permitiendo que el c√°ncer se maneje como una afecci√≥n cr√≥nica, con identificaci√≥n precisa y tratamientos revolucionarios.\n",
            "*   **Fusi√≥n del espacio f√≠sico y virtual:** La l√≠nea entre el espacio f√≠sico y lo virtual se borrar√°, con tecnolog√≠as de inteligencia artificial conectando a las personas a nivel humano, incluso cuando est√°n f√≠sicamente separadas.\n",
            "*   **Mitigaci√≥n del cambio clim√°tico:** Se ampliar√°n las tecnolog√≠as de emisi√≥n negativa, como la eliminaci√≥n de di√≥xido de carbono, para eliminar cantidades relevantes de CO2 del aire y limitar el calentamiento global.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al hacer una pregunta m√°s espec√≠fica:"
      ],
      "metadata": {
        "id": "WqA-92qa40Pw"
      },
      "id": "WqA-92qa40Pw"
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¬øA qu√© se refieren con 'La privacidad estar√° generalizada y priorizada'\"\n",
        "\n",
        "respuesta = rag_chain.invoke({\"question\": pregunta})\n",
        "\n",
        "print(\"üß† Pregunta:\", pregunta)\n",
        "print(\"\\nüìå Respuesta de Gemini:\\n\")\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZiToqme4jri",
        "outputId": "f1625160-4c95-4b4a-b696-c3111f284052"
      },
      "id": "TZiToqme4jri",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Pregunta: ¬øA qu√© se refieren con 'La privacidad estar√° generalizada y priorizada'\n",
            "\n",
            "üìå Respuesta de Gemini:\n",
            "\n",
            "Con \"La privacidad estar√° generalizada y priorizada\" se refieren a que la capacidad de los consumidores para proteger y controlar sus activos de datos confidenciales se convertir√° en la norma, no en la excepci√≥n. Las tecnolog√≠as de mejora de la privacidad se consolidar√°n como una categor√≠a tecnol√≥gica propia y ser√°n un componente esencial en las estrategias de privacidad y seguridad de las empresas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b3eff7",
      "metadata": {
        "id": "c3b3eff7"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ Resumen de este cuaderno\n",
        "\n",
        "En este notebook vimos:\n",
        "\n",
        "- C√≥mo configurar **Gemini** en Google Colab usando `langchain-google-genai`.  \n",
        "- C√≥mo cargar un **PDF** con `PyPDFLoader`.  \n",
        "- C√≥mo dividir el documento en **chunks** con `RecursiveCharacterTextSplitter`.  \n",
        "- C√≥mo generar **embeddings** con `GoogleGenerativeAIEmbeddings`.  \n",
        "- C√≥mo construir una base vectorial con **FAISS**.  \n",
        "- C√≥mo implementar una cadena **RAG** con LCEL para hacer preguntas sobre el PDF.\n",
        "\n",
        "Este cuaderno sirve como plantilla base para extensiones posteriores: integraci√≥n con m√°s tipos de documentos,\n",
        "uso de otros almacenes vectoriales, o construcci√≥n de interfaces (por ejemplo, Gradio o Streamlit).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > 05_BD_vectores_requirements.txt"
      ],
      "metadata": {
        "id": "i03hldpXA9uH"
      },
      "id": "i03hldpXA9uH",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ce9201e69f74ec59a68f66fbe440e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f0184a8f3574fb4a0b039f8baa3823b",
              "IPY_MODEL_9d7e2a3a69fb4e10afa06781397e536d",
              "IPY_MODEL_b20b284ddea14bcca74fb66f2da95ba6"
            ],
            "layout": "IPY_MODEL_3b153d2d130c487d8af0d79157feb502"
          }
        },
        "0f0184a8f3574fb4a0b039f8baa3823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07408d95dac8495a9b3ec3304c1d0dfc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7b338d4603b5447b97ab280bb20318d4",
            "value": "Download‚Äácomplete:‚Äá"
          }
        },
        "9d7e2a3a69fb4e10afa06781397e536d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f124eb69e194623a67c4e4350e774ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea808fbcedaf46029e138c5cbe2f4853",
            "value": 1
          }
        },
        "b20b284ddea14bcca74fb66f2da95ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08582fc29caf44a28c3a394689dc46a0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ec738af94f7640559f43da7646fb1b03",
            "value": "‚Äá67.2M/?‚Äá[00:20&lt;00:00,‚Äá99.0MB/s]"
          }
        },
        "3b153d2d130c487d8af0d79157feb502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07408d95dac8495a9b3ec3304c1d0dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b338d4603b5447b97ab280bb20318d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f124eb69e194623a67c4e4350e774ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ea808fbcedaf46029e138c5cbe2f4853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08582fc29caf44a28c3a394689dc46a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec738af94f7640559f43da7646fb1b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41e12b93d02848568f1ae35d34407be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0acc3fdbe58444eba55051f5384cf97",
              "IPY_MODEL_a8f1a1eab935476784b75a3f14913610",
              "IPY_MODEL_073512fedafa4665b91d46de584edf15"
            ],
            "layout": "IPY_MODEL_339e62957d5d485aa81e24c1ccf73292"
          }
        },
        "d0acc3fdbe58444eba55051f5384cf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7566967d99349f1bd9cf5320cb638b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3bcb9529adbc49b2a57815254d8387ad",
            "value": "Fetching‚Äá5‚Äáfiles:‚Äá100%"
          }
        },
        "a8f1a1eab935476784b75a3f14913610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af36f334d1514bb9be01fa7e776cb776",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56c8de3ac5bb49be824f3a261ba26874",
            "value": 5
          }
        },
        "073512fedafa4665b91d46de584edf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df700a1dfd0476ea77ba368ed42c761",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a65aa957ed048e69958c0793b80f497",
            "value": "‚Äá5/5‚Äá[00:00&lt;00:00,‚Äá‚Äá2.38it/s]"
          }
        },
        "339e62957d5d485aa81e24c1ccf73292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7566967d99349f1bd9cf5320cb638b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcb9529adbc49b2a57815254d8387ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af36f334d1514bb9be01fa7e776cb776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c8de3ac5bb49be824f3a261ba26874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df700a1dfd0476ea77ba368ed42c761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a65aa957ed048e69958c0793b80f497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}